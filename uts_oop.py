# -*- coding: utf-8 -*-
"""UTS_OOP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dOJcTkARuPYebsCOg5z15lbeYB4hUotf
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
import matplotlib.pyplot as plt
import pickle as pkl

class ChurnPredictionModel:
    def __init__(self):
        self.OneHotEncoder = OneHotEncoder()
        self.RF_accuracy = None
        self.RF_class = RandomForestClassifier(max_depth=4)
        self.RF_model = RandomForestClassifier(max_depth=4)
        self.RF_predictions = None
        self.RandomForestClassifier = RandomForestClassifier
        self.XGB_Class = None
        self.XGB_accuracy = None
        self.XGB_model = None
        self.XGB_predictions = None
        self.accuracy_score = accuracy_score
        self.best_accuracy = None
        self.best_model = None
        self.boxplot = None
        self.classification_report = classification_report
        self.cont_enc_test = None
        self.cont_enc_train = None
        self.df = None
        self.filename = 'XGB_churn.pkl'
        self.filename_subs = 'OHC_encoded_cont.pkl'
        self.input_df = None
        self.np = np
        self.output_df = None
        self.pd = pd
        self.pkl = pkl
        self.plt = plt
        self.subs_enc_test = None
        self.subs_enc_train = None
        self.train_encoded_cont = OneHotEncoder()
        self.train_encoded_subs = OneHotEncoder()
        self.train_test_split = train_test_split
        self.x_test = None

    def load_data(self, filename):
        self.df = self.pd.read_csv(filename)

    def preprocess_data(self):
        # Perform data preprocessing steps here
        pass

    def train_random_forest(self):
        # Train Random Forest model here
        pass

    def train_xgboost(self):
        # Train XGBoost model here
        pass

    def evaluate_models(self):
        # Evaluate the trained models here
        pass

    def save_model(self, model, filename):
        with open(filename, 'wb') as file:
            self.pkl.dump(model, file)

    def load_model(self, filename):
        with open(filename, 'rb') as file:
            model = self.pkl.load(file)
        return model

    def visualize_results(self):
        # Visualize the results here
        pass

# Example usage:
model = ChurnPredictionModel()
model.load_data('Data A.csv')
model.preprocess_data()
model.train_random_forest()
model.train_xgboost()
model.evaluate_models()
model.save_model(model.RF_model, model.filename)
loaded_model = model.load_model(model.filename)
model.visualize_results()